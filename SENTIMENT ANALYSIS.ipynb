{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "match = finds the first occurence of pattern in the string\n",
    "\n",
    "search = locates the pattern in the string\n",
    "\n",
    "findall = find all occurences of patterns in the string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REGULAR EXPRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"My name is Oreoluwa\"\n",
    "pattern = \"My\"\n",
    "pattern_2 = \"is\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 2), match='My'>\n"
     ]
    }
   ],
   "source": [
    "mo = re.match(pattern, string)\n",
    "print(mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(8, 10), match='is'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo = re.search(pattern_2, string)\n",
    "mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is']\n"
     ]
    }
   ],
   "source": [
    "mo = re.findall(pattern_2, string)\n",
    "print(mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"my date is 03-06-2020 and theirs is 14-09-2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"\\d{2}-\\d{2}-\\d{4}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = re.findall(pattern, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['03-06-2020', '14-09-2021']\n"
     ]
    }
   ],
   "source": [
    "print (mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wild', 'wild']\n"
     ]
    }
   ],
   "source": [
    "string = \"An eagle is a wild bird and a wild animal\"\n",
    "pattern = \"wild\"\n",
    "mo = re.findall(pattern, string)\n",
    "print(mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to find the position of the letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "mo = re.finditer(pattern, string)\n",
    "\n",
    "for m in mo:\n",
    "    print(m.start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An eagle is a domestic bird and a domestic animal\n"
     ]
    }
   ],
   "source": [
    "string = \"An eagle is a wild bird and a wild animal\"\n",
    "pattern = \"wild\"\n",
    "print(re.sub(pattern, \"domestic\", string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"An eagle is a wild bird and a wild animal\"\n",
    "pattern = \"wild\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEXT PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORPUS, TOKENS & N- GRAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Corpus - collection of text documents\n",
    "\n",
    "- Corpus > Documents > Paragraphs > Sentences > Tokens\n",
    "\n",
    "- Tokens: smaller units of a text (words, phrases, ngrams)\n",
    "\n",
    "- Ngrams: combination of N words/ characters together\n",
    "\n",
    "Example: I love my nails\n",
    "\n",
    "Unigram (n=1) I, love, my, nails\n",
    "\n",
    "Bigrams (n=2) I love, love my, my nails\n",
    "\n",
    "Trigrams (n=3) I love my, love my nails "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOKENIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Process of splitting a text object into small units (token)\n",
    "- Smaller Units: words, numbers, symbols, ngrams, characters\n",
    "- White space tokenizer/ Unigram tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eg\n",
    "\n",
    "- White Space tokenizer\n",
    "\n",
    "Sentence- \"I went to New York to play football\"\n",
    "\n",
    "Tokens - \"I\", \"went\", \"to\", \"New-York\", \"to\" \"play\" \"football\"\n",
    "\n",
    "- Regular expression\n",
    "\n",
    "Sentence - \"Football,Cricket;Golf,Tennis\"\n",
    "\n",
    "Tokens- \"Football\", \"Cricket\", \"Golf\", \"Tennis\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NORMALIZATION\n",
    "\n",
    "It is a process of converting a token to into its base (morpheme). There are 2 types \n",
    "\n",
    "1. Lemmatization\n",
    "\n",
    "2. Stemming\n",
    "\n",
    "\n",
    "- Morpheme: base form of a word\n",
    "\n",
    "- Structure of token: prefix > morpheme > suffix> \n",
    "\n",
    "Eg\n",
    "\n",
    "Antinationalist = anti + nation+ al + ist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEMMING\n",
    "\n",
    "Its the elementary rule based process of removal of inflectional forms of a token. It outputs  the stem of a word.\n",
    "\n",
    "laughing > laughed\n",
    "\n",
    "The stem word is laugh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEMMATIZATION\n",
    "\n",
    "It is the systemmatic process that reduces a token to its lemma.\n",
    "\n",
    "Eg\n",
    "\n",
    "are, am, is - lemma is be\n",
    "\n",
    "running, ran, runs- run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART OF SPEECH TAGS\n",
    "\n",
    "They define syntactic context and role of words in a sentence. \n",
    "\n",
    "Common POS tags include, noun, verb, adjective & adverbs.\n",
    "\n",
    "They are defined by their relationship with the adjacent words in the sentence.\n",
    "\n",
    "Uses: Text Cleaning, Feature Engineering & Text Disambiguation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://courses.analyticsvidhya.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
